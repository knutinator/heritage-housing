{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# Predict House Prices - ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "*   Find and evaluate a regression model to predict house prices\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HousePricesRecords.csv\n",
    "* Instructions on variable selection and data transformation/cleaning from Data Cleaning and Feature Engineering notebooks\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* ML pipeline to predict house price\n",
    "* Feature Importance Plot\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* Running the RandomForestRegressor algorithm on the two features 'OverallQual' and 'GrLivArea' produces the highest result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXKlJFX0iuM5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import most of the needed things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import combinations\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xk7DU_ekbtX8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\"))\n",
    "  \n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXKlJFX0iuM5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vars for custom pipeline classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical mapping dictionary\n",
    "cat_map = {'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0},\n",
    " 'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0},\n",
    "  'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0},\n",
    "   'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
    "\n",
    "# Variables with missing data\n",
    "vars_with_missing_data = ['2ndFlrSF', 'BedroomAbvGr', 'BsmtFinType1', 'GarageFinish',\n",
    "                          'GarageYrBlt', 'LotFrontage', 'MasVnrArea']     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom classes for pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on conclusions from Data Cleaning and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_drop):\n",
    "        self.features_to_drop = features_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy.drop(self.features_to_drop, axis=1, inplace=True)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_map):\n",
    "        self.cat_map = cat_map\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for column, mapping in self.cat_map.items():\n",
    "            X_transformed[column] = X_transformed[column].map(mapping)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingDataImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='median'):\n",
    "        self.strategy = strategy\n",
    "        self.imputer = SimpleImputer(strategy=self.strategy)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy = pd.DataFrame(self.imputer.transform(X_copy), columns=X_copy.columns)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSmartCorrelatedSelection(SmartCorrelatedSelection):\n",
    "    def __init__(self, method='spearman', threshold=0.6, selection_method='variance'):\n",
    "        super().__init__(variables=[], method=method, threshold=threshold, selection_method=selection_method)\n",
    "        self.correlated_feature_sets_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "            return super().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.column] = np.log(X_copy[self.column])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline = Pipeline([\n",
    "        (\"drop_features\", DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF'])),\n",
    "        (\"categorical_mapper\", CategoricalMapper(cat_map)),\n",
    "        ('missing_data_imputer', MissingDataImputer(strategy='median')),\n",
    "        ('corr_sel', CustomSmartCorrelatedSelection(method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDmjjF3tHuCU"
   },
   "source": [
    "Custom Class for hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpTcVDtQ5RMc"
   },
   "outputs": [],
   "source": [
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD6B3CuhiDMT"
   },
   "source": [
    "## Split Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pFzP2iGiIk1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split Train Test Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-15-sWUST6XX"
   },
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTFXq-ieogBj"
   },
   "source": [
    "### Use default hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZKV86gsPw8c"
   },
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGABtSoSLP9u"
   },
   "source": [
    "Do a hyperparameter optimisation search using default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_q-ru92GiBb",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7p56nXeoqWo"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mq4YlrmZooiw"
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pRUAeoG9lrZ"
   },
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2XCyOYkAYpZ"
   },
   "source": [
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyjC7ThFAYKY"
   },
   "outputs": [],
   "source": [
    "# Extensive search on the most suitable model to find the best hyperparameter configuration\n",
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\":{'model__n_estimators': [100,50,150],\n",
    "                           'model__max_depth': [None, 3, 15],\n",
    "                           'model__min_samples_split': [2, 50],\n",
    "                           'model__min_samples_leaf': [1,50],\n",
    "    },\n",
    "    \"RandomForestRegressor\":{'model__n_estimators': [100,50, 140],\n",
    "                             'model__max_depth': [None,4, 15],\n",
    "                             'model__min_samples_split': [2,50],\n",
    "                             'model__min_samples_leaf': [1,50],\n",
    "                             'model__max_leaf_nodes': [None,50],\n",
    "    },\n",
    "    \"LinearRegression\":{},\n",
    "    \"GradientBoostingRegressor\":{'model__n_estimators': [100,50,140],\n",
    "                                 'model__learning_rate':[0.1, 0.01, 0.001],\n",
    "                                 'model__max_depth': [3,15, None],\n",
    "                                 'model__min_samples_split': [2,50],\n",
    "                                 'model__min_samples_leaf': [1,50],\n",
    "                                 'model__max_leaf_nodes': [None,50],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBy8thxqAlrd"
   },
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_4Ob7heAYM9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtNJJpLEAzdP"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjauRLNHAYPr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the four algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWryh7BlA2df"
   },
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[28,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[47,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[47,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ3u0TodDdOZ"
   },
   "source": [
    "# Which pipeline to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE5va8Cr-CCy"
   },
   "source": [
    "We fitted pipelines with four different algorithms:\n",
    "\n",
    "    * ExtraTreesRegressor\n",
    "    * RandomForestRegressor\n",
    "    * LinearRegression\n",
    "    * GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor  performs the best, with a mean R2 score of 0.791839 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BqT1Kne54Fq"
   },
   "source": [
    "# Refit pipeline with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the RandomForestRegressor only used two features, 'OverallQual' and 'GrLivArea' for training, we can rewrite the pipeline to use only these variables. We comment out the unneeded pipeline steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline = Pipeline([\n",
    "        #(\"drop_features\", DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF'])),\n",
    "        #(\"categorical_mapper\", CategoricalMapper(cat_map)),\n",
    "        #('missing_data_imputer', MissingDataImputer(strategy='median')),\n",
    "        #('corr_sel', CustomSmartCorrelatedSelection(method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        #(\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpgS-AgU6IWx"
   },
   "source": [
    "## Split Train Test Set, only with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohPWfCs2E_3G"
   },
   "source": [
    "Subset Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUEIfyLU6IWz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.filter(best_features)\n",
    "X_test = X_test.filter(best_features)\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fT_mdLWFJFz"
   },
   "source": [
    "## Grid Search CV â€“ Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfKEBTyLeDtj"
   },
   "source": [
    "We are using the same model from the previous GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1qcZktreHH5"
   },
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"RandomForestRegressor\":{'model__n_estimators': [100],\n",
    "                             'model__max_depth': [None],\n",
    "                             'model__min_samples_split': [2],\n",
    "                             'model__min_samples_leaf': [1],\n",
    "                             'model__max_leaf_nodes': [50],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEZYXLRQfvTL"
   },
   "source": [
    "Run GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msJPkpo8fFAI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display summary to show correct pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TE6Xgvif1ek"
   },
   "source": [
    "Get pipeline from summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf6qYXV06q9O"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect selected pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7fjgzReFYeM"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPeKtw3A59C3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBtppR73G1Yx"
   },
   "source": [
    "# Generate files for dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShuJ5tYUC06o"
   },
   "source": [
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Modeling pipeline\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vBpPvnaG5Mb"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/predict_house_price/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TvoMsi3DNw1"
   },
   "source": [
    "## Train Set: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJHmwyqgDOr1"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh6w6R7tDOvM"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB6pjmAcDOym"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ93HN6cDPBN"
   },
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVbS3OnRDYtJ"
   },
   "source": [
    "## Test Set: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbgF38n1DaPp"
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9lM0xDvDaVZ"
   },
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Jz66iMaDacI"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weYaJ4UxDake"
   },
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-XpkYAPFncu"
   },
   "source": [
    "## Modelling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLmFFWF6RGo6"
   },
   "source": [
    "ML pipeline for predicting sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQkr4rcrHDnn"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrZPif2aHdyO"
   },
   "outputs": [],
   "source": [
    "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/best_regressor_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTJlYRC5Q2wJ"
   },
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SfLH05-Q2D8"
   },
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-Hc2H3dQ74Z"
   },
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Modeling and Evaluation - Predict Tenure.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
   "language": "python",
   "name": "python381264bit3812pyenvf5c13913cc4f4d82b066f0ed1174e5be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
