{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# Predict House Prices - ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "*   Find and evaluate a regression model to predict house prices\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HousePricesRecords.csv\n",
    "* Instructions on variable selection and data transformation/cleaning from Data Cleaning and Feature Engineering notebooks\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* ML pipeline to predict house price\n",
    "* Feature Importance Plot\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/heritage-housing/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/heritage-housing'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXKlJFX0iuM5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codeany/.local/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import combinations\n",
    "from functools import reduce\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xk7DU_ekbtX8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706.0</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978.0</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486.0</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0     856.0     854.0           3.0           No       706.0          GLQ   \n",
       "1    1262.0       0.0           3.0           Gd       978.0          ALQ   \n",
       "2     920.0     866.0           3.0           Mn       486.0          GLQ   \n",
       "\n",
       "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
       "0      150.0            0.0       548.0          RFn  ...         65.0   \n",
       "1      284.0            NaN       460.0          RFn  ...         80.0   \n",
       "2      434.0            0.0       608.0          RFn  ...         68.0   \n",
       "\n",
       "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0       196.0        61.0            5            7        856.0         0.0   \n",
       "1         0.0         0.0            8            6       1262.0         NaN   \n",
       "2       162.0        42.0            5            7        920.0         NaN   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       2003          2003     208500  \n",
       "1       1976          1976     181500  \n",
       "2       2001          2002     223500  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\"))\n",
    "  \n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXKlJFX0iuM5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vars for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical mapping dictionary\n",
    "cat_map = {'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0},\n",
    " 'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0},\n",
    "  'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0},\n",
    "   'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
    "\n",
    "# Variables with missing data\n",
    "vars_with_missing_data = ['2ndFlrSF', 'BedroomAbvGr', 'BsmtFinType1', 'GarageFinish',\n",
    "                          'GarageYrBlt', 'LotFrontage', 'MasVnrArea']     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom classes for pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on conclusions from Data Cleaning and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_drop):\n",
    "        self.features_to_drop = features_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy.drop(self.features_to_drop, axis=1, inplace=True)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_map):\n",
    "        self.cat_map = cat_map\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for column, mapping in self.cat_map.items():\n",
    "            X_transformed[column] = X_transformed[column].map(mapping)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingDataImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='median'):\n",
    "        self.strategy = strategy\n",
    "        self.imputer = SimpleImputer(strategy=self.strategy)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy = pd.DataFrame(self.imputer.transform(X_copy), columns=X_copy.columns)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "class CustomSmartCorrelatedSelection(SmartCorrelatedSelection):\n",
    "    def __init__(self, method='spearman', threshold=0.6, selection_method='variance'):\n",
    "        super().__init__(variables=[], method=method, threshold=threshold, selection_method=selection_method)\n",
    "        self.correlated_feature_sets_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "            return super().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.column] = np.log(X_copy[self.column])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinSF1',\n",
      "       'BsmtFinType1', 'BsmtUnfSF', 'EnclosedPorch', 'GarageArea',\n",
      "       'GarageFinish', 'GarageYrBlt', 'GrLivArea', 'KitchenQual', 'LotArea',\n",
      "       'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'OverallCond',\n",
      "       'OverallQual', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd',\n",
      "       'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline = Pipeline([\n",
    "        (\"drop_features\", DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF'])),\n",
    "        (\"categorical_mapper\", CategoricalMapper(cat_map)),\n",
    "        ('missing_data_imputer', MissingDataImputer(strategy='median')),\n",
    "        ('corr_sel', CustomSmartCorrelatedSelection(method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDmjjF3tHuCU"
   },
   "source": [
    "Custom Class for hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NpTcVDtQ5RMc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD6B3CuhiDMT"
   },
   "source": [
    "## Split Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-pFzP2iGiIk1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (1168, 23) (1168,) \n",
      "* Test set: (292, 23) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Train Test Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-15-sWUST6XX"
   },
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTFXq-ieogBj"
   },
   "source": [
    "### Use default hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XZKV86gsPw8c"
   },
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGABtSoSLP9u"
   },
   "source": [
    "Do a hyperparameter optimisation search using default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-_q-ru92GiBb",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for DecisionTreeRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for AdaBoostRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7p56nXeoqWo"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mq4YlrmZooiw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.672712</td>\n",
       "      <td>0.800495</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.073092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.632989</td>\n",
       "      <td>0.791839</td>\n",
       "      <td>0.85964</td>\n",
       "      <td>0.083685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.701462</td>\n",
       "      <td>0.77925</td>\n",
       "      <td>0.824712</td>\n",
       "      <td>0.041363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.639305</td>\n",
       "      <td>0.763939</td>\n",
       "      <td>0.850056</td>\n",
       "      <td>0.083875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.637822</td>\n",
       "      <td>0.738218</td>\n",
       "      <td>0.821103</td>\n",
       "      <td>0.070041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.621051</td>\n",
       "      <td>0.721318</td>\n",
       "      <td>0.794948</td>\n",
       "      <td>0.063986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.495511</td>\n",
       "      <td>0.623105</td>\n",
       "      <td>0.674645</td>\n",
       "      <td>0.067497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score max_score std_score\n",
       "3        ExtraTreesRegressor  0.672712   0.800495  0.867736  0.073092\n",
       "2      RandomForestRegressor  0.632989   0.791839   0.85964  0.083685\n",
       "0           LinearRegression  0.701462    0.77925  0.824712  0.041363\n",
       "5  GradientBoostingRegressor  0.639305   0.763939  0.850056  0.083875\n",
       "6               XGBRegressor  0.637822   0.738218  0.821103  0.070041\n",
       "4          AdaBoostRegressor  0.621051   0.721318  0.794948  0.063986\n",
       "1      DecisionTreeRegressor  0.495511   0.623105  0.674645  0.067497"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pRUAeoG9lrZ"
   },
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2XCyOYkAYpZ"
   },
   "source": [
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lyjC7ThFAYKY"
   },
   "outputs": [],
   "source": [
    "# Extensive search on the most suitable model to find the best hyperparameter configuration\n",
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\":{'model__n_estimators': [100,50,150],\n",
    "                           'model__max_depth': [None, 3, 15],\n",
    "                           'model__min_samples_split': [2, 50],\n",
    "                           'model__min_samples_leaf': [1,50],\n",
    "    },\n",
    "    \"RandomForestRegressor\":{'model__n_estimators': [100,50, 140],\n",
    "                             'model__max_depth': [None,4, 15],\n",
    "                             'model__min_samples_split': [2,50],\n",
    "                             'model__min_samples_leaf': [1,50],\n",
    "                             'model__max_leaf_nodes': [None,50],\n",
    "    },\n",
    "    \"LinearRegression\":{},\n",
    "    \"GradientBoostingRegressor\":{'model__n_estimators': [100,50,140],\n",
    "                                 'model__learning_rate':[0.1, 0.01, 0.001],\n",
    "                                 'model__max_depth': [3,15, None],\n",
    "                                 'model__min_samples_split': [2,50],\n",
    "                                 'model__min_samples_leaf': [1,50],\n",
    "                                 'model__max_leaf_nodes': [None,50],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBy8thxqAlrd"
   },
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_4Ob7heAYM9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtNJJpLEAzdP"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjauRLNHAYPr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWryh7BlA2df"
   },
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[28,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[47,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[47,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 4\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ3u0TodDdOZ"
   },
   "source": [
    "# Which pipeline to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE5va8Cr-CCy"
   },
   "source": [
    "We fitted 3 pipelines:\n",
    "* Regression\n",
    "* Regression with PCA\n",
    "* Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQR54xeCbIAH"
   },
   "source": [
    "The regressor pipelines didn't reach the expected performance threshold (0.7 R2 score) for the train and test set.\n",
    "\n",
    "The classifier was tuned on Recall for class 0 (tenure <4 months), since we are interested to detect prospects that may churn soon. \n",
    "* It has reasonable performance for class 0 (<4 months) and class 2 (+20 months)\n",
    "* Class 1 (4 to 20 months) has weak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BqT1Kne54Fq"
   },
   "source": [
    "# Refit pipeline with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['Contract', 'PaymentMethod'])),\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        # feature selection is not needed\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpgS-AgU6IWx"
   },
   "source": [
    "## Split Train Test Set, only with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_31XFcrg6IWy",
    "tags": []
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_clf.drop(['tenure'], axis=1),\n",
    "    df_clf['tenure'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohPWfCs2E_3G"
   },
   "source": [
    "Subset Best Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUEIfyLU6IWz",
    "tags": []
   },
   "source": [
    "X_train = X_train.filter(best_features)\n",
    "X_test = X_test.filter(best_features)\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fT_mdLWFJFz"
   },
   "source": [
    "## Grid Search CV â€“ Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfKEBTyLeDtj"
   },
   "source": [
    "We are using the same model from the previous GridCV search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1qcZktreHH5"
   },
   "source": [
    "models_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WaSA9jcecXr"
   },
   "source": [
    "And the best parameters from the previous GridCV search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXi0L025eKA6"
   },
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7jAkvlBeeQl"
   },
   "source": [
    "You will need to type in manually since the hyperparameter values have to be a list. The previous dictionary is not in this format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9HBXI2E58_5"
   },
   "source": [
    "params_search = {'AdaBoostClassifier':  {\n",
    "    'model__learning_rate': [0.001],   # the value should be in []\n",
    "    'model__n_estimators': [50]       # the value should be in []\n",
    "}\n",
    "}\n",
    "params_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEZYXLRQfvTL"
   },
   "source": [
    "GridSearch CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msJPkpo8fFAI",
    "tags": []
   },
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring = make_scorer(recall_score, labels=[0], average=None),\n",
    "           n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcgDvuLRfwsE"
   },
   "source": [
    "\n",
    "Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loZEVp8g6q9O"
   },
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TE6Xgvif1ek"
   },
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf6qYXV06q9O"
   },
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeB08Md3f60p"
   },
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuA9mpyk6q9P"
   },
   "source": [
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN0aj0iv6q9P"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dN-blGZb6q9P",
    "tags": []
   },
   "source": [
    "# how many data cleaning and feature engineering does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 1\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(pipeline_clf.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng,\n",
    "    'Importance': pipeline_clf['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7fjgzReFYeM"
   },
   "source": [
    "## Evaluate Classifier on Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPeKtw3A59C3",
    "tags": []
   },
   "source": [
    "clf_performance(X_train=X_train, y_train=y_train,\n",
    "                        X_test=X_test, y_test=y_test,\n",
    "                        pipeline=pipeline_clf,\n",
    "                        label_map= label_map )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBtppR73G1Yx"
   },
   "source": [
    "# Push files to the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShuJ5tYUC06o"
   },
   "source": [
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Modeling pipeline\n",
    "* label map\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vBpPvnaG5Mb"
   },
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_tenure/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TvoMsi3DNw1"
   },
   "source": [
    "## Train Set: features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJHmwyqgDOr1"
   },
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yh6w6R7tDOvM"
   },
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pB6pjmAcDOym"
   },
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZ93HN6cDPBN"
   },
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVbS3OnRDYtJ"
   },
   "source": [
    "## Test Set: features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbgF38n1DaPp"
   },
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9lM0xDvDaVZ"
   },
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Jz66iMaDacI"
   },
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weYaJ4UxDake"
   },
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-XpkYAPFncu"
   },
   "source": [
    "## Modelling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLmFFWF6RGo6"
   },
   "source": [
    "ML pipeline for predicting tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQkr4rcrHDnn"
   },
   "source": [
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrZPif2aHdyO"
   },
   "source": [
    "joblib.dump(value=pipeline_clf, filename=f\"{file_path}/clf_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUCrXGvUFpeB"
   },
   "source": [
    "## List  mapping target levels to ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFkAKp0eRMYM"
   },
   "source": [
    "Map for converting numerical variable to categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6HfkzarHHbW"
   },
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPEpdAgPHQaL"
   },
   "source": [
    "joblib.dump(value=label_map, filename=f\"{file_path}/label_map.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTJlYRC5Q2wJ"
   },
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SfLH05-Q2D8"
   },
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Hc2H3dQ74Z"
   },
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh0SKfv_s-3V"
   },
   "source": [
    "Good job! Clear cell's outputs, push to the repo using git commands and move on to the next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Modeling and Evaluation - Predict Tenure.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
   "language": "python",
   "name": "python381264bit3812pyenvf5c13913cc4f4d82b066f0ed1174e5be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
